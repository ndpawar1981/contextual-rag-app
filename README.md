<h1 align="center">ğŸ§  Contextual RAG Assistant</h1>

<p align="center">
  <b>A Modular, Context-Aware Retrieval Augmented Generation System Built with LangChain, ChromaDB, OpenAI & Streamlit</b>
  <br/>
  <sub>Featuring contextual chunking, citations, sources, and a beautiful streaming Chat UI.</sub>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue" />
  <img src="https://img.shields.io/badge/Framework-LangChain-green" />
  <img src="https://img.shields.io/badge/Frontend-Streamlit-red" />
  <img src="https://img.shields.io/badge/VectorDB-ChromaDB-purple" />
  <img src="https://img.shields.io/badge/License-MIT-yellow" />
</p>

---

## ğŸš€ Overview

**Contextual RAG Assistant** is a full-stack, production-ready RAG (Retrieval Augmented Generation) application that:

âœ” Loads and processes PDFs  
âœ” Generates **context-enriched chunks using an LLM**  
âœ” Stores embeddings in **ChromaDB**  
âœ” Retrieves top-K relevant chunks  
âœ” Generates answers with **citations**, **sources**, and **justifications**  
âœ” Provides a **modern Streamlit UI** with a **typing / character stream effect**  
âœ” Fully modular â€” loader, retriever, generator, and UI separated into clean Python modules  

This project converts a notebook into a scalable codebase suitable for real production RAG systems.

---

## ğŸ“ Project Structure

```

ğŸ“¦ rag_app/
â”‚
â”œâ”€â”€ app.py                 # Streamlit UI with streaming chat output
â”œâ”€â”€ config.py              # Centralized configuration (models, paths, chunk size, etc.)
â”œâ”€â”€ loader.py              # Document loader + contextual chunk generator + vector store builder
â”œâ”€â”€ retriever.py           # ChromaDB retriever wrapper
â”œâ”€â”€ generator.py           # RAG pipelines: basic, with sources, with citations
â”‚
â”œâ”€â”€ requirements.txt       # All dependencies
â””â”€â”€ README.md              # This file

````

---

## âœ¨ Features

### ğŸ” Contextual Chunk Generation  
Chunks are not just split â€” they are enhanced by an LLM that explains:

- Where the chunk fits in the document  
- Its role (intro/methods/analysis/etc.)  
- Why it is useful  

â†’ This drastically improves retrieval quality.

---

### ğŸ“š Multiple RAG Modes

| Mode | Description |
|------|-------------|
| **Answer Only** | Just the generated answer |
| **Answer + Sources** | Returns exact chunks used to answer |
| **Answer + Citations** | Structured citations with page, title, quote |

---

### ğŸ¨ Beautiful Streamlit UI

- Character-by-character message streaming  
- Chat-style interface using `st.chat_message`  
- Sidebar for:  
  - API key  
  - Uploading PDFs  
  - Rebuilding vector index  
  - Selecting retrieval top-K  
  - Selecting output mode  

---

## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>
````

---

### 2ï¸âƒ£ Create a virtual environment

**Windows:**

```bash
python -m venv venv
venv\Scripts\Activate.ps1
```

**Mac / Linux:**

```bash
python3 -m venv venv
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Add your OpenAI key

Either:

#### Option A â€” Add `.env` file

```
OPENAI_API_KEY=sk-xxxx
```

or

#### Option B â€” Paste API key into sidebar in the Streamlit app.

---

## â–¶ï¸ Running the App

```bash
streamlit run app.py
```

Open your browser at:

```
http://localhost:8501
```

---

## ğŸ“‚ Uploading and Indexing Documents

1. Upload one or more PDFs
2. Click **"Build / Refresh Vector Index"**
3. The system will:

   * Load PDFs
   * Generate contextual chunks
   * Embed them
   * Save them into ChromaDB
4. Ask any question in the chat!

---

## ğŸ§© Modular Architecture

### **loader.py**

* Loads PDF pages
* Splits them using `RecursiveCharacterTextSplitter`
* Calls the LLM to generate contextual descriptions
* Creates ChromaDB vector index

---

### **retriever.py**

* Wraps a similarity retriever over ChromaDB
* Acts as the retrieval pipeline for all RAG modes

---

### **generator.py**

Contains 3 RAG pipelines:

1. **Basic RAG**
2. **RAG + Sources**
3. **RAG + Structured Citations** (Pydantic model)

---

### **app.py**

* Streamlit chat UI
* Real-time typing animation
* File uploader + index builder
* Chat history persistence

## ğŸ¤ Contributing

Pull requests are welcome!

If you'd like to:

* Improve UI
* Add agentic tools
* Add telemetry
* Add reranking
* Add Docker support

Just open an issue.

---

## ğŸ“œ License

MIT License â€” free for personal & commercial use.

---

## â­ Support the Project

If you found this project helpfulâ€¦

**Please â­ star the repo!**
